{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Reference taken from :\nhttps://github.com/TheIndependentCode/Neural-Network","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)","metadata":{"_uuid":"5e079ad0-3738-4047-8999-085b64e297d0","_cell_guid":"f588e3be-ab3a-4d8c-9bbb-109201b26de4","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-08-30T05:50:50.934031Z","iopub.execute_input":"2022-08-30T05:50:50.934717Z","iopub.status.idle":"2022-08-30T05:50:50.941688Z","shell.execute_reply.started":"2022-08-30T05:50:50.934653Z","shell.execute_reply":"2022-08-30T05:50:50.940063Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"#Loss function \ndef mse(y_true,y_pred):\n    return np.mean((y_pred-y_true)**2)\n\ndef mse_prime(y_true,y_pred):\n    return 2*(y_pred-y_true)/y_true.size;","metadata":{"execution":{"iopub.status.busy":"2022-08-30T05:50:50.944939Z","iopub.execute_input":"2022-08-30T05:50:50.946174Z","iopub.status.idle":"2022-08-30T05:50:50.955697Z","shell.execute_reply.started":"2022-08-30T05:50:50.946111Z","shell.execute_reply":"2022-08-30T05:50:50.954114Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"class Layer():\n    def __init__(self,n_inputs,n_outputs):\n        #self.weights=0.10*np.random.randn(n_outputs,n_inputs)\n        self.weights=0.10*np.random.randn(n_outputs,n_inputs)   \n        self.bias=np.ones((n_outputs,1))\n        \n    def forward_propagation(self,inputs):\n        self.input=inputs\n        self.output=np.dot(self.weights,inputs)+self.bias\n        return self.output\n    \n    def backward_propagation(self,output_gradient,learning_rate):\n        weights_gradient=np.dot(output_gradient,self.input.T)\n        input_gradient=np.dot(self.weights.T,output_gradient)\n        self.weights-=learning_rate*weights_gradient\n        self.bias-=learning_rate*output_gradient        \n        return input_gradient","metadata":{"_uuid":"5e079ad0-3738-4047-8999-085b64e297d0","_cell_guid":"f588e3be-ab3a-4d8c-9bbb-109201b26de4","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-08-30T05:50:50.957539Z","iopub.execute_input":"2022-08-30T05:50:50.957990Z","iopub.status.idle":"2022-08-30T05:50:50.970049Z","shell.execute_reply.started":"2022-08-30T05:50:50.957952Z","shell.execute_reply":"2022-08-30T05:50:50.968956Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"class Activation():\n    def __init__(self,activation_func,activation_prime_func):\n        self.activation=activation_func\n        self.activation_prime=activation_prime_func\n        \n        \n    def forward_propagation(self,inputs):\n        self.input=inputs\n        self.output=self.activation(inputs)\n        return self.output\n    \n    def backward_propagation(self,output_gradient,learning_rate):\n        #element wise multiply\n        return np.multiply(output_gradient, self.activation_prime(self.input))\n        \n        ","metadata":{"execution":{"iopub.status.busy":"2022-08-30T05:50:50.971916Z","iopub.execute_input":"2022-08-30T05:50:50.972702Z","iopub.status.idle":"2022-08-30T05:50:50.981603Z","shell.execute_reply.started":"2022-08-30T05:50:50.972660Z","shell.execute_reply":"2022-08-30T05:50:50.980212Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"#Activation functions\nclass Sigmoid(Activation):\n    \n    def __init__(self):\n    \n        def sigmoid(z):\n            return 1/(1-np.exp(-z))\n\n        def sigmoid_prime(z):\n            s=sigmoid(z)\n            return s*(1-s)\n\n\n        super().__init__(sigmoid,sigmoid_prime)\n\n   ","metadata":{"execution":{"iopub.status.busy":"2022-08-30T05:50:50.984908Z","iopub.execute_input":"2022-08-30T05:50:50.986209Z","iopub.status.idle":"2022-08-30T05:50:50.995632Z","shell.execute_reply.started":"2022-08-30T05:50:50.986140Z","shell.execute_reply":"2022-08-30T05:50:50.994473Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"def train(network,X_train,y_train,loss,loss_prime,epochs=1000,learning_rate=0.01,verbose=True):\n    for e in range(epochs):\n        error=0\n        for x,y in zip(X_train,y_train):\n            \n            #forward propagation\n            output=x\n            for layer in network:\n                #output=layer.forward_propagation(output-np.max(output))\n                output=layer.forward_propagation(output)\n                #print('output = ',output)\n            \n            #Loss\n            #output_clip=np.clip(output,1e-7,1-1e-7)\n            error+=loss(y,output)\n            \n            #Backward propagation\n            \n            #error derivative (for last layer)\n            grad=loss_prime(y,output)\n            #print('y=',y,' output= ',output)\n            #print('last layer grad = ',grad)\n            \n            for layer in reversed(network):\n                grad = layer.backward_propagation(grad,learning_rate)\n                \n        error/=len(X_train)\n        \n        if verbose:\n        #if e%50==0:\n            print(\"{}/{} error={}\".format(e+1,epochs,error))\n            \n            ","metadata":{"execution":{"iopub.status.busy":"2022-08-30T05:53:15.412851Z","iopub.execute_input":"2022-08-30T05:53:15.413901Z","iopub.status.idle":"2022-08-30T05:53:15.425781Z","shell.execute_reply.started":"2022-08-30T05:53:15.413668Z","shell.execute_reply":"2022-08-30T05:53:15.424360Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"def predict(network,x):\n    #same as forward propagation\n    output=x\n    for layer in network:\n        output=layer.forward_propagation(output)\n    \n    return output\n        ","metadata":{"execution":{"iopub.status.busy":"2022-08-30T05:57:16.963431Z","iopub.execute_input":"2022-08-30T05:57:16.964018Z","iopub.status.idle":"2022-08-30T05:57:16.971614Z","shell.execute_reply.started":"2022-08-30T05:57:16.963967Z","shell.execute_reply":"2022-08-30T05:57:16.969927Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"\nX = np.reshape([[0, 0], [0, 1], [1, 0], [1, 1]], (4, 2, 1))\n#Y = np.reshape([[0], [1], [1], [0]], (4, 1, 1))\nY = np.reshape([[0], [0], [0], [1]], (4, 1, 1))  #and operator\n\nnetwork = [\n    Layer(2, 3),\n    Sigmoid(),\n    Layer(3, 1),\n    Sigmoid()\n]\n\ntrain(network,  X, Y,mse, mse_prime, epochs=1000, learning_rate=0.01)","metadata":{"execution":{"iopub.status.busy":"2022-08-30T05:50:51.043728Z","iopub.execute_input":"2022-08-30T05:50:51.044284Z","iopub.status.idle":"2022-08-30T05:50:51.052462Z","shell.execute_reply.started":"2022-08-30T05:50:51.044240Z","shell.execute_reply":"2022-08-30T05:50:51.051103Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}